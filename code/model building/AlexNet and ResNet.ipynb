{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyHBsmynZac2",
        "outputId": "8cd7bed0-02ea-4f57-d0ab-a228037940e3"
      },
      "id": "QyHBsmynZac2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a250ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00a250ef",
        "outputId": "7b54b629-01b1-4924-be84-79b6af272560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import np_utils\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "\n",
        "\n",
        "# animal categories\n",
        "categories = ['mountain','ocean','street','forest']\n",
        "no_cate=len(categories)\n",
        "no_cate #number of categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T-78AK3yWezs",
      "metadata": {
        "id": "T-78AK3yWezs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbdb076-0ec8-4ce8-f677-86440a1ec288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5600, 224, 224, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(5600, 4)\n",
            "(1200, 4)\n",
            "(1200, 4)\n"
          ]
        }
      ],
      "source": [
        "# load dataï¼Œ\n",
        "path ='/content/drive/MyDrive/project/train_test_val_XY.npz'\n",
        "train_test_val_XY = np.load(path)\n",
        "\n",
        "# extract data\n",
        "trainX = train_test_val_XY['trainX']\n",
        "trainY = train_test_val_XY['trainY']\n",
        "\n",
        "testX = train_test_val_XY['testX']\n",
        "testY = train_test_val_XY['testY']\n",
        "\n",
        "validationX = train_test_val_XY['validationX']\n",
        "validationY = train_test_val_XY['validationY']\n",
        "\n",
        "print(trainX.shape)\n",
        "print(validationX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(validationY.shape)\n",
        "print(testY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b05Yc22da_X",
      "metadata": {
        "id": "7b05Yc22da_X"
      },
      "source": [
        "# **Model Fitting 1: AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z8aRrul4dhna",
      "metadata": {
        "id": "z8aRrul4dhna"
      },
      "outputs": [],
      "source": [
        "HEIGHT =224\n",
        "WIDTH =224\n",
        "N_CHANNELS = 3\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Convolution2D(filters=96, input_shape=(HEIGHT,WIDTH,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Convolution2D(filters=256, kernel_size=(5,5), strides=1, padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Convolution2D(filters=384, kernel_size=(3,3), strides=1, padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Convolution2D(filters=384, kernel_size=(3,3), strides=1, padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Convolution2D(filters=256, kernel_size=(3,3), strides=1, padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.2))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(no_cate))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LW1xC_IcuaWm",
      "metadata": {
        "id": "LW1xC_IcuaWm"
      },
      "outputs": [],
      "source": [
        "# Define learning rate\n",
        "# lr_candidate = [0.0001, 0.001, 0.01, 0.1]\n",
        "\n",
        "# Define epochs\n",
        "epochs = 200\n",
        "\n",
        "# Define learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Define optimzer w.r.t. different learning rate\n",
        "opt = Adam(learning_rate=lr)\n",
        "\n",
        "# Initialize tensorboard\n",
        "logdir = os.path.join(\"/content/drive/MyDrive/project/logs\", \"lr = \" + str(lr))\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Model Compile\n",
        "AlexNet.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Model fitting (training)\n",
        "AlexNet.fit(trainX,trainY,\n",
        "            batch_size=128, \n",
        "            epochs=epochs,\n",
        "            validation_data=(validationX,validationY),\n",
        "            callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard"
      ],
      "metadata": {
        "id": "SdjMP9PaBTtg"
      },
      "id": "SdjMP9PaBTtg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorboard --logdir logs --port=6009"
      ],
      "metadata": {
        "id": "PGw_Ue5firIj"
      },
      "id": "PGw_Ue5firIj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet.save(\"/content/drive/MyDrive/project/alexnet\" + str(lr) + \".h5\")"
      ],
      "metadata": {
        "id": "l32x9St9pZMQ"
      },
      "id": "l32x9St9pZMQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p6teC-coC33Y",
      "metadata": {
        "id": "p6teC-coC33Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cfe215-5c81-41a5-f900-dcce3e6f1a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 1s 19ms/step - loss: 1.4772 - accuracy: 0.7517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4772168397903442, 0.7516666650772095]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "AlexNet.evaluate(testX,testY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mXe39zAzhgwn",
      "metadata": {
        "id": "mXe39zAzhgwn"
      },
      "source": [
        "# **Model Fitting 2: ResNet34**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XQPix7eAhfwq",
      "metadata": {
        "id": "XQPix7eAhfwq"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,padding=\"SAME\", use_bias=False)\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "  def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.activation = keras.activations.get(activation)\n",
        "    self.main_layers = [\n",
        "                        DefaultConv2D(filters, strides=strides),\n",
        "                        keras.layers.BatchNormalization(),\n",
        "                        self.activation,\n",
        "                        DefaultConv2D(filters),\n",
        "                        keras.layers.BatchNormalization()\n",
        "    ]\n",
        "    self.skip_layers = []\n",
        "    if strides > 1:\n",
        "      self.skip_layers = [\n",
        "                          DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
        "                          keras.layers.BatchNormalization()\n",
        "      ]\n",
        "\n",
        "def call(self, inputs):\n",
        "  Z = inputs\n",
        "  for layer in self.main_layers:\n",
        "    Z = layer(Z)\n",
        "  skip_Z = inputs\n",
        "  for layer in self.skip_layers:\n",
        "    skip_Z = layer(skip_Z)\n",
        "  return self.activation(Z + skip_Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h5tSxmoKm0xs",
      "metadata": {
        "id": "h5tSxmoKm0xs"
      },
      "outputs": [],
      "source": [
        "resnet34 = keras.models.Sequential()\n",
        "resnet34.add(DefaultConv2D(64, kernel_size=7, strides=2,input_shape=[224,224, 3]))\n",
        "resnet34.add(keras.layers.BatchNormalization())\n",
        "resnet34.add(keras.layers.Activation(\"relu\"))\n",
        "resnet34.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "  strides = 1 if filters == prev_filters else 2\n",
        "  resnet34.add(ResidualUnit(filters, strides=strides))\n",
        "  prev_filters = filters\n",
        "\n",
        "resnet34.add(keras.layers.GlobalAvgPool2D())\n",
        "resnet34.add(keras.layers.Flatten())\n",
        "resnet34.add(keras.layers.Dense(4, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28GqJ7qS7yJi"
      },
      "outputs": [],
      "source": [
        "# Define learning rate\n",
        "# lr_candidate = [0.0001, 0.001]\n",
        "\n",
        "# Define epochs\n",
        "epochs = 200\n",
        "\n",
        "# Define learning rate\n",
        "lr = 0.0001\n",
        "\n",
        "# Define optimzer w.r.t. different learning rate\n",
        "opt = Adam(learning_rate=lr)\n",
        "\n",
        "# Initialize tensorboard\n",
        "logdir = os.path.join(\"/content/drive/MyDrive/project/logs\", \"resnet34\", \"lr = \" + str(lr))\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# logdir = os.path.join(\"logs\", \"vgg\", \"lr = \" + str(lr))\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Model Compile\n",
        "resnet34.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Model fitting (training)\n",
        "resnet34.fit(trainX,trainY,\n",
        "            batch_size=64,\n",
        "            epochs=epochs,\n",
        "            validation_data=(validationX,validationY),\n",
        "            callbacks=[tensorboard_callback])\n",
        "\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "# reconstructed_model = keras.models.load_model(\"model.h5\")"
      ],
      "id": "28GqJ7qS7yJi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BrPNTVWdnD_R",
      "metadata": {
        "id": "BrPNTVWdnD_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3678a18c-6f36-4286-bc65-0e346715dd50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 12ms/step - loss: 0.7422 - accuracy: 0.7192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7422178387641907, 0.7191666960716248]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "resnet34.evaluate(testX,testY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet34.save_weights(\"/content/drive/Shareddrives/zhufang147/resnet34\" + str(lr) + \".ckpt\")"
      ],
      "metadata": {
        "id": "r0isGrBzBuyg"
      },
      "id": "r0isGrBzBuyg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "N_7P5l_hnJ2T",
      "metadata": {
        "id": "N_7P5l_hnJ2T"
      },
      "source": [
        "\n",
        "# **Model Fitting 3: ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wm6qCZINnOyY",
      "metadata": {
        "id": "Wm6qCZINnOyY"
      },
      "outputs": [],
      "source": [
        "class ResidualUnit(keras.layers.Layer):\n",
        "  def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.activation = keras.activations.get(activation)\n",
        "    self.main_layers = [\n",
        "                        DefaultConv2D(filters, kernel_size=1,strides=1),\n",
        "                        keras.layers.BatchNormalization(),\n",
        "                        self.activation,\n",
        "                        DefaultConv2D(filters, kernel_size=3,strides=strides),\n",
        "                        keras.layers.BatchNormalization(),\n",
        "                        self.activation,\n",
        "                        DefaultConv2D(filters*4,kernel_size=1,strides=1),\n",
        "                        keras.layers.BatchNormalization()\n",
        "    ]\n",
        "    self.skip_layers = []\n",
        "    if strides > 1:\n",
        "      self.skip_layers = [\n",
        "                          DefaultConv2D(filters*4, kernel_size=1, strides=strides),\n",
        "                          keras.layers.BatchNormalization()\n",
        "      ]\n",
        "\n",
        "def call(self, inputs):\n",
        "  Z = inputs\n",
        "  for layer in self.main_layers:\n",
        "    Z = layer(Z)\n",
        "  skip_Z = inputs\n",
        "  for layer in self.skip_layers:\n",
        "    skip_Z = layer(skip_Z)\n",
        "  return self.activation(Z + skip_Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wazWZ8-AnSBj",
      "metadata": {
        "id": "wazWZ8-AnSBj"
      },
      "outputs": [],
      "source": [
        "resnet50 = keras.models.Sequential()\n",
        "resnet50.add(DefaultConv2D(64, kernel_size=7, strides=2,input_shape=[224, 224, 3]))\n",
        "resnet50.add(keras.layers.BatchNormalization())\n",
        "resnet50.add(keras.layers.Activation(\"relu\"))\n",
        "resnet50.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "  strides = 1 if filters == prev_filters else 2\n",
        "  resnet50.add(ResidualUnit(filters, strides=strides))\n",
        "  prev_filters = filters\n",
        "\n",
        "resnet50.add(keras.layers.GlobalAvgPool2D())\n",
        "resnet50.add(keras.layers.Flatten())\n",
        "resnet50.add(keras.layers.Dense(4, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bG81bVVMnVVB",
      "metadata": {
        "id": "bG81bVVMnVVB"
      },
      "outputs": [],
      "source": [
        "# Define learning rate\n",
        "# lr_candidate = [0.0001, 0.001]\n",
        "\n",
        "# Define epochs\n",
        "epochs = 200\n",
        "\n",
        "# Define learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Define optimzer w.r.t. different learning rate\n",
        "opt = Adam(learning_rate=lr)\n",
        "\n",
        "# Initialize tensorboard\n",
        "logdir = os.path.join(\"/content/drive/MyDrive/project/logs\", \"resnet50\", \"lr = \" + str(lr))\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# logdir = os.path.join(\"logs\", \"vgg\", \"lr = \" + str(lr))\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Model Compile\n",
        "resnet50.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Model fitting (training)\n",
        "resnet50.fit(trainX,trainY,\n",
        "            batch_size=64,\n",
        "            epochs=epochs,\n",
        "            validation_data=(validationX,validationY),\n",
        "            callbacks=[tensorboard_callback])\n",
        "\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "# reconstructed_model = keras.models.load_model(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NiPTE9aonfKV",
      "metadata": {
        "id": "NiPTE9aonfKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dddf115-442e-4288-b9aa-20f32bf57e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8486 - accuracy: 0.6617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8485937714576721, 0.6616666913032532]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "resnet50.evaluate(testX,testY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "XhFGqogy2CKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8426e73-5127-4d98-9854-7f5e48736c4d"
      },
      "id": "XhFGqogy2CKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 13 15:41:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    26W /  70W |  14586MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vB_bhz0HFKZg"
      },
      "id": "vB_bhz0HFKZg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "main_modified.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}