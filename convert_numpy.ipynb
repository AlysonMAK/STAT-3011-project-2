{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a250ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00a250ef",
        "outputId": "cde54463-18ed-4691-f595-e35b570daec8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow import keras\n",
        "\n",
        "# path to images\n",
        "# path = '/content/drive/MyDrive/Intel dataset/'\n",
        "categories = ['mountain','ocean','street','forest']\n",
        "no_cate=len(categories)\n",
        "no_cate #number of categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200cce90",
      "metadata": {
        "id": "200cce90"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709a11a8",
      "metadata": {
        "id": "709a11a8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ddcc60",
      "metadata": {
        "id": "66ddcc60"
      },
      "source": [
        "Resize pictures to equate height and width for each picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0dc300",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "3c0dc300",
        "outputId": "544aa53b-1886-452a-8b31-d57e25ed5c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['./data_set2000/ocean/ocean902.jpg', 1], ['./data_set2000/forest/forest253.jpg', 3], ['./data_set2000/mountain/mountain1681.jpg', 0], ['./data_set2000/mountain/mountain1560.jpg', 0], ['./data_set2000/street/street1050.jpg', 2], ['./data_set2000/forest/forest1368.jpg', 3], ['./data_set2000/mountain/mountain1019.jpg', 0], ['./data_set2000/mountain/mountain369.jpg', 0], ['./data_set2000/street/street1762.jpg', 2], ['./data_set2000/street/street531.jpg', 2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [09:42<00:00, 13.73it/s]\n"
          ]
        }
      ],
      "source": [
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "imagePaths = []\n",
        "HEIGHT =224\n",
        "WIDTH =224\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# grab the image paths and randomly shuffle them\n",
        "for k, category in enumerate(categories):\n",
        "    for f in os.listdir(path+category):\n",
        "        imagePaths.append([path+category+'/'+f, k]) \n",
        "random.shuffle(imagePaths)\n",
        "print(imagePaths[:10])\n",
        "\n",
        "# loop over the input images\n",
        "for imagePath in tqdm(imagePaths):\n",
        "    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\n",
        "    # aspect ratio) and store the image in the data list\n",
        "    \n",
        "    image = cv2.imread(imagePath[0])\n",
        "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\n",
        "    data.append(image)     \n",
        "    \n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "    label = imagePath[1]\n",
        "    labels.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OUZxhH1z2kWM",
      "metadata": {
        "id": "OUZxhH1z2kWM"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2385263f",
      "metadata": {
        "id": "2385263f"
      },
      "outputs": [],
      "source": [
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c6674d",
      "metadata": {
        "id": "25c6674d"
      },
      "outputs": [],
      "source": [
        "np.savez('./save_data_labels',data=data,labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b4d68ab",
      "metadata": {
        "id": "2b4d68ab"
      },
      "outputs": [],
      "source": [
        "(trainX,testX,trainY,testY)=train_test_split(data,labels,test_size=0.15,random_state=3011,stratify=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdc4e60",
      "metadata": {
        "id": "dfdc4e60"
      },
      "outputs": [],
      "source": [
        "np.savez('./train_testXY', \n",
        "        trainX = trainX, \n",
        "        testX = testX,\n",
        "        trainY = trainY,\n",
        "        testY = testY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50793998",
      "metadata": {
        "id": "50793998"
      },
      "source": [
        "train-validation-test splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c034a9",
      "metadata": {
        "id": "17c034a9"
      },
      "outputs": [],
      "source": [
        "train_testXY = np.load('./train_testXY.npz')\n",
        "\n",
        "trainX = train_testXY['trainX']\n",
        "trainY = train_testXY['trainY']\n",
        "\n",
        "testX = train_testXY['testX']\n",
        "testY = train_testXY['testY']\n",
        "\n",
        "#further split train data to get validation dataset\n",
        "(trainX,validationX,trainY,validationY)=train_test_split(trainX,trainY,test_size=15/85,random_state=3011,stratify=trainY)\n",
        "\n",
        "\n",
        "validationY = np_utils.to_categorical(validationY,no_cate)\n",
        "trainY = np_utils.to_categorical(trainY,no_cate)\n",
        "testY = np_utils.to_categorical(testY,no_cate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04074c26",
      "metadata": {
        "id": "04074c26"
      },
      "outputs": [],
      "source": [
        "np.savez('./train_test_val_XY', \n",
        "        trainX = trainX, \n",
        "        testX = testX,\n",
        "        validationX = validationX,\n",
        "        trainY = trainY,\n",
        "        testY = testY,\n",
        "        validationY = validationY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T-78AK3yWezs",
      "metadata": {
        "id": "T-78AK3yWezs"
      },
      "outputs": [],
      "source": [
        "trainX = train_test_val_XY['trainX']\n",
        "trainY = train_test_val_XY['trainY']\n",
        "\n",
        "testX = train_test_val_XY['testX']\n",
        "testY = train_test_val_XY['testY']\n",
        "\n",
        "validationX = train_test_val_XY['validationX']\n",
        "validationY = train_test_val_XY['validationY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FkUZg-gmXCs8",
      "metadata": {
        "id": "FkUZg-gmXCs8",
        "outputId": "ddddfa25-fb29-4249-aed4-eab79cb9b5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5600, 224, 224, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(5600, 4)\n",
            "(1200, 4)\n",
            "(1200, 4)\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape)\n",
        "print(validationX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(validationY.shape)\n",
        "print(testY.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "convertnumpy.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3aba073aa02e20a67fdc2cf463595dade8c25aa80d88a63f86b87b0fcbcbeac3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}